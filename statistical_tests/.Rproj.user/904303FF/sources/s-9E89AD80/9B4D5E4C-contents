---
title: "Unknown map experiment - average navigation time"
output:
  html_notebook: default
---

We are analyzing if offloading any of the three functionalities (i.e., SLAM, navigation and object recognition) has a statistically significant effect on the average navigation time. Fist, install and load the required libraries:
```{r}
if (!require('tidyverse')) install.packages('tidyverse', dependencies = TRUE); library('tidyverse')
if (!require('ggpubr')) install.packages('ggpubr', dependencies = TRUE); library('ggpubr')
if (!require('rstatix')) install.packages('rstatix', dependencies = TRUE); library('rstatix')
if (!require('ggplot2')) install.packages('ggplot2', dependencies = TRUE); library('ggplot2')
if (!require('lmPerm')) install.packages('lmPerm', dependencies = TRUE); library('lmPerm')
if (!require('emmeans')) install.packages('emmeans', dependencies = TRUE); library('emmeans')
```

Next, load the experiment results from the csv file:
```{r}
data <- read.csv(file = '../../raw_data/unknown_map_experiment/run_table.csv')
data$avg_navigation_time_s <- (data$avg_goal_sending_delay_ms + data$avg_goal_processing_s*1000 + data$avg_nav_result_delay_ms)/1000
data <- subset(data, select = c(X__run_id, slam_offloaded, navigation_offloaded, obj_recognition_offloaded, avg_navigation_time_s))
data$slam_offloaded <- as.factor(data$slam_offloaded)
data$navigation_offloaded <- as.factor(data$navigation_offloaded)
data$obj_recognition_offloaded <- as.factor(data$obj_recognition_offloaded)
data$avg_navigation_time_s <- as.numeric(data$avg_navigation_time_s)
```

Mean and standard deviation of the average navigation time for each treatment are displayed in the summary below:
```{r}
data %>%
  group_by(slam_offloaded, navigation_offloaded, obj_recognition_offloaded) %>%
  get_summary_stats(avg_navigation_time_s, type = "mean_sd")
```

# Three-Way ANOVA test

Since there are three independent variables in the experiment, we opt for three-way ANOVA test. First, we need to check if all assumptions for performing the test are met. The fist assumption of having independent observations is met inherently according to the way the experiment itself is conducted. 

## No extreme outliers assumption

Next, we need to check if there are any extreme outliers:

```{r}
data %>%
  group_by(slam_offloaded, navigation_offloaded, obj_recognition_offloaded) %>%
  identify_outliers(avg_navigation_time_s)
```
The results show that there are only two outliers, for runs 80 and 37, respectfully, but neither is not considered as extreme in terms of statistical significance. We can proceed with the other assumptions.

## Normality assumption by analyzing the model residuals

The first way to check normality assumption is by analyzing the model residuals:

```{r}
model  <- lm(avg_navigation_time_s ~ slam_offloaded*navigation_offloaded*obj_recognition_offloaded, data = data)
ggqqplot(residuals(model))
```
The QQ plot in the figure above shows that residuals are approximately alongside the reference line. From this observation, we can assume that normality constraint is satisfied. Nevertheless, we perform Shapiro-Wilk test to confirm this conclusion:
```{r}
shapiro_test(residuals(model)) %>%
  add_significance()
```
The p-value of `0.323` shows that we cannot formally reject $H_0$, which states that the data is indeed normally distributed. This is aligned with the conclusion drawn from the QQ plot.

## Normality assumption by each group

The other way to check normality is by analyzing if samples for each possible treatment combination are normally distributed:
```{r}
data %>%
  group_by(slam_offloaded, navigation_offloaded, obj_recognition_offloaded) %>%
  shapiro_test(avg_navigation_time_s) %>%
  add_significance()
```

Shapiro-Wilk test per each group yields p-value higher than `0.05`, hence we cannot reject null hypothesis. Samples per group are thus normally distributed, which is complement with the conclusion from QQ-plots per group below, where all data points seem to be aligned with the reference line:
```{r}
ggqqplot(data, "avg_navigation_time_s", ggtheme = theme_bw()) +
  facet_grid(slam_offloaded + navigation_offloaded ~ obj_recognition_offloaded, labeller = "label_both")
```

## Homogeneity of variance assumption

Homogeneity of variance assumption can be checked via Leveneâ€™s test:

```{r}
data %>% 
  levene_test(avg_navigation_time_s ~ slam_offloaded*navigation_offloaded*obj_recognition_offloaded) %>%
  add_significance()
```
Since the p-value is higher than `0.05`, the result of the Levene's test is not statistically significant, hence the assumption for homogeneity of variance holds.

## Test execution

Since all the assumptions for applying three-way ANOVA test hold, we can proceed with the computation:
```{r}
data %>% 
  anova_test(avg_navigation_time_s ~ slam_offloaded*navigation_offloaded*obj_recognition_offloaded)
```
Test results show that the main effect for object recognition is significant, but there is also a significant two-way interaction between SLAM and object recognition. The eta-squared effect sizes are:
```{r}
res.aov <- aov(avg_navigation_time_s ~ slam_offloaded*navigation_offloaded*obj_recognition_offloaded, data = data)
eta_squared(res.aov)
```

## Pairwise comparisons for significant slam_offloaded:obj_recognition_offloaded two-way interaction 

Since we have a significant two-way interaction between SLAM and object recognition, we need to perform multiple pairwise comparison to determine which group means are different. We will use estimated marginal means test for this purpose with Bonferroni adjustment. We will group the result by object recognition, since the main effect of object recognition is significant according to three-way ANOVA results:
```{r}
data %>% 
  group_by(obj_recognition_offloaded) %>%
  emmeans_test(avg_navigation_time_s ~ slam_offloaded, p.adjust.method = "bonferroni") 
```
However, the results for neither of the groups seem significant. If we try to apply the same test, but grouped by SLAM instead:
```{r}
data %>% 
  group_by(slam_offloaded) %>%
  emmeans_test(avg_navigation_time_s ~ obj_recognition_offloaded, p.adjust.method = "bonferroni") 
```
We can see that effect of offloading object recognition is significant only when SLAM is executed onboard. 

# Results

In the box plot below, we can indeed see that when SLAM is executed onboard, the average navigation time is lower when object recognition is offloaded. However, when SLAM is offloaded, offloading object recognition does not have significant effect on the average navigation time:
```{r}
ggplot(data, aes(x = slam_offloaded, y = avg_navigation_time_s, fill = obj_recognition_offloaded)) +
  theme_bw() + 
  geom_boxplot(width = 0.5, outlier.size = 0.5) + 
  stat_summary(fun = mean, color = 'black', geom = 'point', shape = 5) +
  labs(x = "SLAM offloaded", y = "Average navigation time (s)") +
  guides(fill=guide_legend(title="Object recognition offloaded")) +
  theme(
    axis.title.x = element_text(size = 12, family = 'sans'),
    axis.title.y = element_text(size = 12, family = 'sans'),
    axis.text.x = element_text(size = 11, family = 'sans'),
    axis.text.y = element_text(size = 11, family = 'sans'),
    
  )
```