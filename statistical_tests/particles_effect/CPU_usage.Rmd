---
title: "Effect of the number of SLAM filter particles parameter on the average CPU usage"
output:
  html_notebook: default
---

We need to analyse the impact of two possible values for the number of SLAM filter particles on the average CPU usage. We have chosen two values for the number of particles, namely, `5`, which is used in the primary experiments, and `30`, which is the default value in Gmapping ROS package. First, let us load the necessary libraries:
```{r}
if (!require('tidyverse')) install.packages('tidyverse', dependencies = TRUE); library('tidyverse')
if (!require('ggpubr')) install.packages('ggpubr', dependencies = TRUE); library('ggpubr')
if (!require('rstatix')) install.packages('rstatix', dependencies = TRUE); library('rstatix')
if (!require('ggplot2')) install.packages('ggplot2', dependencies = TRUE); library('ggplot2')
if (!require('coin')) install.packages('coin', dependencies = TRUE); library('coin')
```

Next, we load the raw data output of the performed experiment:
```{r}
data <- read.csv(file = '../../raw_data/test_particles/run_table.csv')
data <- subset(data, select = c(X__run_id, particles, avg_cpu_util))
data$particles <- as.factor(data$particles)
data$avg_cpu_util <- as.numeric(data$avg_cpu_util)
```

Mean and standard deviation of the average CPU usage for both particle number values are displayed in the summary below:
```{r}
data %>%
  group_by(particles) %>%
  get_summary_stats(avg_cpu_util, type = "mean_sd")
```

We can visualize the distribution of the data for both particle number treatments via boxplot below:
```{r}
#pdf(file = "../../figures/particles_effect/cpu-usage.pdf")

ggplot(data, aes(x = particles, y = avg_cpu_util, fill = particles)) +
  theme_bw() + 
  geom_boxplot(width = 0.9, outlier.size = 0.5) + 
  stat_summary(fun = mean, color = 'black', geom = 'point', shape = 5, size = 1.5) +
  labs(x = "Number of SLAM filter particles (#)", y = "Average CPU usage (%)") +
  theme(legend.position = 'none') +
  theme(
    axis.title.x = element_text(size = 12, family = 'sans'),
    axis.title.y = element_text(size = 12, family = 'sans'),
    axis.text.x = element_text(size = 11, family = 'sans'),
    axis.text.y = element_text(size = 11, family = 'sans')
  )

#dev.off()
```

# Welch's t-test

We will apply the Welch's t-test to compare the means of both treatments. This is the default t-test in R and the safer alternative to standard Student's t-test, when we cannot assume that variances of both treatments are equal. However, we still need to check if other assumptions for applying this test are met. The first assumption of having independent observations, i.e. each subject belongs to only one group and there are no relationships between observations within the two groups, is satisfied inherently by the very way in which the experiment is conducted.

## No significant outliers

Next assumption that we need to check is if there are no significant outliers in neither of the two groups:
```{r}
data %>% 
  group_by(particles) %>%
  identify_outliers(avg_cpu_util)
```

As the result above shows, there are indeed no significant outliers thus we can proceed with other assumptions.

## Normality

Next, we need to check if data in both groups stem from a normal distribution. To do so, we first need to draw QQ-plot for both groups:
```{r}
ggqqplot(data, x = "avg_cpu_util", facet.by = "particles")
```
Data points on both figures seem to be aligned alongside the respective reference lines hence we can assume that normality assumption is satisfied for both particle number treatment groups. Nevertheless, we need to perform Shapiro-Wilk test for each group to confirm the assumptions drawn from the QQ-plots:
```{r}
data %>%
  group_by(particles) %>%
  shapiro_test(avg_cpu_util)
```
As the results of the test show, p-values for both groups are higher than `0.05` reference value (`p = 0.737` and `p = 0.574`, respectfully), which means that we cannot reject the null-hypothesis stating that the data within both groups are normally distributed. Hereby, we conclude that the normality assumption for both groups is satisfied.

## Computation

Since we established that there are no extreme outliers and the data for both groups is normally distributed, we can proceed with the execution of Welch's t-test:
```{r}
data %>%
  t_test(avg_cpu_util ~ particles) %>%
  add_significance()
```
The resulting p-value of $2.68 \cdot 10^{-19}$ is much lower than `0.05` reference value for the `0.95` confidence interval. This means that the obtained p-value is statistically significant and we can reject $H_0$, which states that the means of the average CPU usage for both particle number values are equal. We can hereby conclude that the number of filter particles parameter has a statistically significant effect on the average CPU usage.

## Effect size

We establish with Welch's t-test results that the particle number parameter has a statistically significant effect on the average CPU usage. Now we need to perform Cohen's d test to estimate the magnitude of the said effect:

```{r}
data %>%
  cohens_d(avg_cpu_util ~ particles)
```
The resulting effect size of `d = -29.56164` is interpreted as _large_ in R, according to the Cohen's rule of thumb^[http://www.utstat.toronto.edu/~brunner/oldclass/378f16/readings/CohenPower.pdf]. According to the new and extended rules of thumb defined by Sawilowsky, the magnitude for this d-value is considered as _huge_^[https://digitalcommons.wayne.edu/cgi/viewcontent.cgi?article=1536&context=jmasm]. This is indeed clear from the distribution of data for both treatments in the boxplot above, where we can see that the average CPU usage mean for `5` particles is `30.783%`, while it is `43.671%` for `30` particles. The resulting d-value is negative since the average CPU usage mean for `5` particles group is lower than the one for `10` particles.

