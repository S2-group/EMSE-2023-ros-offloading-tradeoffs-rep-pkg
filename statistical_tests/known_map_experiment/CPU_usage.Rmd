---
title: "Known map experiment - CPU usage"
output:
  html_notebook: default
---

We are analyzing if offloading any of the three functionalities (i.e., localisation, navigation and object recognition) has a statistically significant effect on the average CPU usage. Fist, install and load the required libraries:
```{r}
if (!require('tidyverse')) install.packages('tidyverse', dependencies = TRUE); library('tidyverse')
if (!require('ggpubr')) install.packages('ggpubr', dependencies = TRUE); library('ggpubr')
if (!require('rstatix')) install.packages('rstatix', dependencies = TRUE); library('rstatix')
if (!require('ggplot2')) install.packages('ggplot2', dependencies = TRUE); library('ggplot2')
if (!require('lmPerm')) install.packages('lmPerm', dependencies = TRUE); library('lmPerm')
if (!require('emmeans')) install.packages('emmeans', dependencies = TRUE); library('emmeans')
```

Next, load the experiment results from the csv file:
```{r}
data <- read.csv(file = '../../raw_data/known_map_experiment/run_table.csv')
data <- subset(data, select = c(X__run_id, amcl_offloaded, navigation_offloaded, obj_recognition_offloaded, avg_cpu_util))
data$amcl_offloaded <- as.factor(data$amcl_offloaded)
data$navigation_offloaded <- as.factor(data$navigation_offloaded)
data$obj_recognition_offloaded <- as.factor(data$obj_recognition_offloaded)
data$avg_cpu_util <- as.numeric(data$avg_cpu_util)
```

Mean and standard deviation of the average CPU usage for each treatment are displayed in the summary below:
```{r}
data %>%
  group_by(amcl_offloaded, navigation_offloaded, obj_recognition_offloaded) %>%
  get_summary_stats(avg_cpu_util, type = "mean_sd")
```

# Three-Way ANOVA test

Since there are three independent variables in the experiment, we opt for three-way ANOVA test. First, we need to check if all assumptions for performing the test are met. The fist assumption of having independent observations is met inherently according to the way the experiment itself is conducted. 

## No extreme outliers assumption

Next, we need to check if there are any extreme outliers:

```{r}
data %>%
  group_by(amcl_offloaded, navigation_offloaded, obj_recognition_offloaded) %>%
  identify_outliers(avg_cpu_util)
```

The results show that there are five outliers, for runs 42, 80, 27, 54 and 9, respectfully, while runs 54 and 9 represent extreme outliers. We should remove the said runs from the dataset, but we can also leave them if we believe that they will not have a significant effect on the obtained results. Let us make an alternative dataset with the extreme outliers being removed:

```{r}
data_without_outliers <- data
data_without_outliers <- data_without_outliers[!(data_without_outliers$X__run_id == 'run_54'),]
data_without_outliers <- data_without_outliers[!(data_without_outliers$X__run_id == 'run_9'),]
```
We proceed to check the next assumption - normality of the data. 

## Normality assumption by analyzing the model residuals

The first way to check normality assumption is by analyzing the model residuals:

```{r}
model  <- lm(avg_cpu_util ~ amcl_offloaded*navigation_offloaded*obj_recognition_offloaded, data = data)
ggqqplot(residuals(model))
```

The QQ-plot in the figure above shows that most of the residuals are approximately alongside the reference line hence we can assume that residuals are normally distributed. We will complement the QQ-plot with Shapiro-Wilk test to conclude if normality is indeed satisfied:
```{r}
shapiro_test(residuals(model)) %>%
  add_significance()
```
The p-value of `0.300` shows that we cannot formally reject $H_0$, which states that the data is normally distributed. We can conclude that the data is indeed normally distributed.

## Normality assumption by each group

The other way to check normality is by analyzing if samples for each possible treatment combination are normally distributed:
```{r}
data %>%
  group_by(amcl_offloaded, navigation_offloaded, obj_recognition_offloaded) %>%
  shapiro_test(avg_cpu_util) %>%
  add_significance()
```

Shapiro-Wilk test yields p-value higher than `0.05` for all groups, except for the two groups. If we execute the test on the dataset without extreme outliers:
```{r}
data_without_outliers %>%
  group_by(amcl_offloaded, navigation_offloaded, obj_recognition_offloaded) %>%
  shapiro_test(avg_cpu_util) %>%
  add_significance()
```
all of the groups are normally distributed since no p-value is lower than `0.05`. The QQ-plots per group are depicted below, where most of the data points seem to be aligned with the reference line:

```{r}
ggqqplot(data, "avg_cpu_util", ggtheme = theme_bw()) +
  facet_grid(amcl_offloaded + navigation_offloaded ~ obj_recognition_offloaded, labeller = "label_both")
```

## Homogeneity of variance assumption

Homogeneity of variance assumption can be checked via Leveneâ€™s test:
```{r}
data %>% 
  levene_test(avg_cpu_util ~ amcl_offloaded*navigation_offloaded*obj_recognition_offloaded) %>%
  add_significance()
```
Since the p-value is higher than `0.05`, the result of the Levene's test is not statistically significant, hence the assumption for homogeneity of variance holds.

## Test execution

Since all the assumptions for applying three-way ANOVA test hold, we can proceed with the computation:
```{r}
data %>% 
  anova_test(avg_cpu_util ~ amcl_offloaded*navigation_offloaded*obj_recognition_offloaded)
```

The main effects for all three independent variables are statistically significant, but also all for all two-way interactions. We need to execute pairwise comparisons for all significant two-way interactions. The eta-squared effect sizes are:
```{r}
res.aov <- aov(avg_cpu_util ~ amcl_offloaded*navigation_offloaded*obj_recognition_offloaded, data = data)
eta_squared(res.aov)
```


## Pairwise comparisons for significant amcl_offloaded:navigation_offloaded two-way interaction 

Since we have a significant two-way interaction between localisation and navigation, we need to perform multiple pairwise comparison to determine which group means are different. We will use estimated marginal means test for this purpose with Bonferroni adjustment. We will group the result by localisation variable:
```{r}
data %>% 
  group_by(amcl_offloaded) %>%
  emmeans_test(avg_cpu_util ~ navigation_offloaded, p.adjust.method = "bonferroni") 
```
However, the results for neither of the groups seem significant. If we try to apply the same test, but grouped by navigation instead:
```{r}
data %>% 
  group_by(navigation_offloaded) %>%
  emmeans_test(avg_cpu_util ~ amcl_offloaded, p.adjust.method = "bonferroni") 
```
We get the same result again, meaning that interaction between localisation and navigation is not significant for neither of the group combinations.

## Pairwise comparisons for significant amcl_offloaded:obj_recognition_offloaded two-way interaction 

Since we have a significant two-way interaction between localisation and object recognition, we need to perform multiple pairwise comparison to determine which group means are different. We will use estimated marginal means test for this purpose with Bonferroni adjustment. We will group the result by object recognition, since the main effect of object recognition is greater than the one of localisation, according to three-way ANOVA results:
```{r}
data %>% 
  group_by(obj_recognition_offloaded) %>%
  emmeans_test(avg_cpu_util ~ amcl_offloaded, p.adjust.method = "bonferroni", detailed = TRUE)
```
We can see that offloading localisation has a significant effect on the average CPU usage when object recognition is both offloaded and not.

## Pairwise comparisons for significant navigation_offloaded:obj_recognition_offloaded two-way interaction 

Since we have a significant two-way interaction between navigation and object recognition, we need to perform multiple pairwise comparison to determine which group means are different. We will use estimated marginal means test for this purpose with Bonferroni adjustment. We will group the result by object recognition, since the main effect of object recognition is greater than the one of navigation, according to three-way ANOVA results:
```{r}
data %>% 
  group_by(obj_recognition_offloaded) %>%
  emmeans_test(avg_cpu_util ~ navigation_offloaded, p.adjust.method = "bonferroni", detailed = TRUE)
```
We can see that offloading navigation has a significant effect on the average CPU usage when object recognition is both offloaded and not.

# Results

In the box plot below, we can indeed see that when object recognition is both offloaded and not, the average CPU usage is lower when localisation is offloaded. However, if we compare the means of two groups on the left and right, when object recognition is not offloaded and offloaded, we can see that offloading object recognition does have an enormous overall effect on the average CPU usage:
```{r}
#pdf(file = "../../figures/known_map_experiment/cpu-usage-1.pdf")

ggplot(data, aes(x = obj_recognition_offloaded, y = avg_cpu_util, fill = amcl_offloaded)) +
  theme_bw() + 
  geom_boxplot(width = 0.9, outlier.size = 0.5) + 
  stat_summary(fun = mean, color = 'black', geom = 'point', shape = 5) +
  labs(x = "Object recognition offloaded", y = "Average CPU usage (%)") +
  guides(fill=guide_legend(title="Localisation offloaded")) +
  theme(
    axis.title.x = element_text(size = 12, family = 'sans'),
    axis.title.y = element_text(size = 12, family = 'sans'),
    axis.text.x = element_text(size = 11, family = 'sans'),
    axis.text.y = element_text(size = 11, family = 'sans'),
    legend.title = element_text(size = 12, family = 'sans'),
    legend.text = element_text(size = 11, family = 'sans'),
    legend.position = "top"
  )

#dev.off()
```

Similarly, in the box plot below, we can see that when object recognition is both offloaded and not, the average CPU usage is lower when navigation is offloaded. However, if we compare the means of two groups on the left and right, when object recognition is not offloaded and offloaded, we can see that offloading object recognition does have an enormous overall effect on the average CPU usage:
```{r}
#pdf(file = "../../figures/known_map_experiment/cpu-usage-2.pdf")

ggplot(data, aes(x = obj_recognition_offloaded, y = avg_cpu_util, fill = navigation_offloaded)) +
  theme_bw() + 
  geom_boxplot(width = 0.9, outlier.size = 0.5) + 
  stat_summary(fun = mean, color = 'black', geom = 'point', shape = 5) +
  labs(x = "Object recognition offloaded", y = "Average CPU usage (%)") +
  guides(fill=guide_legend(title="Navigation offloaded")) +
  theme(
    axis.title.x = element_text(size = 12, family = 'sans'),
    axis.title.y = element_text(size = 12, family = 'sans'),
    axis.text.x = element_text(size = 11, family = 'sans'),
    axis.text.y = element_text(size = 11, family = 'sans'),
    legend.title = element_text(size = 12, family = 'sans'),
    legend.text = element_text(size = 11, family = 'sans'),
    legend.position = "top"
  )

#dev.off()
```
Even though CPU usage is lower when navigation is offloaded, the boxplot above shows that the improvement is not that significant. 
